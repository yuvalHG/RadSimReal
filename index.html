<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="RadSimReal"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>RadSimReal</title>
<!--  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">-->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">RadSimReal: Bridging the Gap Between Synthetic and Real Data in Radar Object Detection With Simulation</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Oded Bialer</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Yuval Haitman</a><sup>*</sup></span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">General Motors, Technical Center Israel<br>CVPR 2024</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
       <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item has-text-centered">
        <!-- Your image here -->
        <img src="static/images/sim_vs_real.png" alt="RadSimReal Vs. Real Radar Images"/>
        <h2 class="subtitle has-text-centered">
          <br>
          Comparison between synthetic and real radar images from different scenarios.<br>
           Each scenario shows the camera image and the corresponding radar image. <br>
          <b>Top.</b> simulation scenarios. <b>Bottom.</b> real scenarios.
        </h2>
      </div>
      <div class="item has-text-centered">
        <!-- Your image here -->
        <img src="static/images/lidar.png" width="75%" alt="Simulation From Lidar"/>
        <h2 class="subtitle has-text-centered">
          <br>
          Comparison between <em>RadSimReal</em> image and a real radar images for the same scenario. <br>
          <b>(a)</b> Camera image of the scenario.
          <b>(b)</b> High-resolution LIDAR points segmented by object type.
          <b>(c)</b> Real radar image.
          <b>(d)</b> <em>RadSimReal</em> image.
          The black points in (c) and (d) represent the LIDAR points.
        </h2>
      </div>
  </div>
</div>
      <h2 class="subtitle has-text-centered">
       This work demonstrates the feasibility of training an object detection model for radar data solely on simulated data, achieving comparable performance to models trained on real radar data, and surpassing those trained on a single real radar dataset and tested on another, thereby showcasing the potential for simulated data in radar object detection training.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Object detection in radar imagery with neural networks shows great potential for improving autonomous driving. However, obtaining annotated datasets from real radar images, crucial for training these networks, is challenging, especially in scenarios with long-range detection and adverse weather and lighting conditions where radar performance excels. To address this challenge, we present RadSimReal, an innovative physical radar simulation capable of generating synthetic radar images with accompanying annotations for various radar types and environmental conditions, all without the need for real data collection. Remarkably, our findings demonstrate that training object detection models on RadSimReal data and subsequently evaluating them on real-world data produce performance levels comparable to models trained and tested on real data from the same dataset, and even achieves better performance when testing across different real datasets. RadSimReal offers advantages over other physical radar simulations that it does not necessitate knowledge of the radar design details, which are often not disclosed by radar suppliers, and has faster run-time. This innovative tool has the potential to advance the development of computer vision algorithms for radar-based autonomous driving applications.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-max-desktop">
  <div class="hero-body is-center has-text-centered">
    <h2 class="title is-3">Method</h2>
   <img src="static/images/method_overview.png" width="60%" alt="Method Overview"/>
    <h2 class="subtitle has-text-centered">
      Block diagram illustrating the processing steps for conventional simulation <b>(a)</b>+<b>(b)</b> and <em>RadSimReal</em> <b>(a)</b>+<b>(c)</b>. <br>
      <b>(a)</b> Simulates the environment to generate reflection points with RF reflectivity of an automotive scene, while <b>(b)</b> and <b>(c)</b> represent the conventional approach and <em>RadSimReal's</em> approach, respectively, for transforming the reflection points into a radar image.
        </h2>
</div>
</section>
<!-- End image carousel -->




<!-- Youtube video -->
<!--<section class="hero is-small is-light">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      &lt;!&ndash; Paper video. &ndash;&gt;-->
<!--      <h2 class="title is-3">Video Presentation</h2>-->
<!--      <div class="columns is-centered has-text-centered">-->
<!--        <div class="column is-four-fifths">-->
<!--          -->
<!--          <div class="publication-video">-->
<!--            &lt;!&ndash; Youtube embed code here &ndash;&gt;-->
<!--            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>-->
<!--          </div>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--  </div>-->
<!--</section>-->
<!-- End youtube video -->


<!-- Video carousel -->
<section class="hero is-small is-light">
  <div class="hero-body is-center has-text-centered">
    <div class="container">
      <h2 class="title is-3">Experimental Results</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <img src="static/images/qualitative_results.png" alt="RadSimReal Vs. Real Radar Images"/>
        <h2 class="subtitle has-text-centered">
          Qualitative comparison of object detection DNN trained on <em>RadSimReal</em> vs. real data from the RADDet dataset.
          Rows correspond to different  scenarios from RADDet test set. (a) Input radar image, (b) `U-Net' model's detection score and bounding boxes trained with RADDet.
          (c) `U-Net' trained with <em>RadSimReal</em> data. Detected and ground truth bounding boxes marked in pink and white, respectively.
        </h2>
        </div>
       <div class="item">
          <img src="static/images/qunatitive_results.png" alt="RadSimReal Vs. Real Radar Images"/>
        <h2 class="subtitle has-text-centered">
          Results
        </h2>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->






<!-- Paper poster -->
<!--<section class="hero is-small is-light">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      <h2 class="title">Poster</h2>-->

<!--      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">-->
<!--          </iframe>-->
<!--        -->
<!--      </div>-->
<!--    </div>-->
<!--  </section>-->
<!--End paper poster -->


<!--BibTex citation -->
<!--  <section class="section" id="BibTeX">-->
<!--    <div class="container is-max-desktop content">-->
<!--      <h2 class="title">BibTeX</h2>-->
<!--      <pre><code>BibTex Code Here</code></pre>-->
<!--    </div>-->
<!--</section>-->
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
